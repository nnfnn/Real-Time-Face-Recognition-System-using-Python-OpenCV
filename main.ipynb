{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b110c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in c:\\users\\victus\\anaconda3\\lib\\site-packages (3.28.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be11f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in c:\\users\\victus\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\victus\\anaconda3\\lib\\site-packages (from face_recognition) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\victus\\anaconda3\\lib\\site-packages (from face_recognition) (9.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\victus\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fae874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4fce3",
   "metadata": {},
   "source": [
    "The face recognilion Ibrary in Pythan is primarily used for facial recognition tasks. Il provides varlous functions to detect, recognize, and manipulate laces in Images and videos. Some of its key functionalities Include:\n",
    "\n",
    "Face Detection: Locating faces within an image or a frame of a video.\n",
    "\n",
    "Facial Landmarks: Identilying specific points on a face, like eyes, nose, mouth, etc.\n",
    "\n",
    "Face Encoding: Generating a numerical representation (face encodings) of a face from an image.\n",
    "\n",
    "Face Recognitton: Comparing face encodings to recognize and match faces across different images or videas. Manipulation:\n",
    "\n",
    "Cropping, resizing, or manipulating faces in images or videos. Face Clustering: Grouping similar faces together based on their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fbf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'IMAGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8809efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "classNames = []\n",
    "\n",
    "mylist = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4065990d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adhi.jpg',\n",
       " 'ali.jpg',\n",
       " 'amar.jpg',\n",
       " 'dk.jpg',\n",
       " 'faf.jpg',\n",
       " 'gill.jpg',\n",
       " 'JELL (1).jpeg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a224e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in mylist:\n",
    "    currentimage=cv2.imread(os.path.join(path,cl))\n",
    "    images.append(currentimage)\n",
    "    classNames.append(os.path.splitext(cl)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1d7a7",
   "metadata": {},
   "source": [
    "* os.path.splitext() seperates the filename into a tuple containing the base name (without the extension)and the extensionÂ itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c5b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findencodings(images):\n",
    "    \n",
    "    encodelist=[]\n",
    "    \n",
    "    \n",
    "    for img in images:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodelist.append(encode)\n",
    "        \n",
    "    return encodelist\n",
    "    \n",
    "encodelistknownfaces = findencodings(images)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f08154",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    sucess,img = cap.read()\n",
    "    imagesmall = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "    \n",
    "    # img: The image you want to resize.\n",
    "    # (0, 0): Output image size. Here, it means the output size will be calculated based on the scaling factors provided.\n",
    "    # None: Not specifying an output size directly.\n",
    "    # 0.25, 0.25: The scaling factors for the horizontal and vertical axes, respectively. In this case, the image will be\n",
    "    # reduced to 25% of its original size in both dimensions.\n",
    "\n",
    "    face_in_frame = face_recognition.face_locations(imagesmall)\n",
    "    \n",
    "    #The face_locations function in face_recognition is used to find face locations (bounding box coordinates) within an image.\n",
    "    # 'face_locations' now contains the bounding box coordinates of detected faces\n",
    "    # [(top, right, bottom, left), ...] for each face found in the image\n",
    "    \n",
    "    encoded_face = face_recognition.face_encodings(imagesmall,face_in_frame)\n",
    "\n",
    "    #printiface in framel\n",
    "\n",
    "    for encodeface, faceloc in zip(encoded_face,face_in_frame): \n",
    "        matches = face_recognition.compare_faces(encodelistknownfaces,encodeface)\n",
    "        \n",
    "        #It appears that you're using the face_recognition library to compare faces. The compare_faces() \n",
    "        #function in this library is typically used to compare a list of known face encodings to \n",
    "        #the encoding of a single face, determining if they match or not.\n",
    "\n",
    "\n",
    "\n",
    "        #encodelistknownfaces: This should be a list containing the known face encodings, usually\n",
    "        #representing the encodings of faces you've already stored or identified as \"known.\"\n",
    "        \n",
    "        #encodeface: This is the face encoding you want to compare against the known faces.\n",
    "        \n",
    "        \n",
    "        facedistance = face_recognition.face_distance(encodelistknownfaces,encodeface)\n",
    "        \n",
    "        #computes the Euclidean distance between a single face encoding (represented by encodeface) and a list of \n",
    "        #known face encodings (in encodelistknownfaces). This distance metric measures the similarity between face \n",
    "        #encodings. Smaller distances indicate more similar faces.\n",
    "\n",
    "\n",
    "        #print(facedistance)\n",
    "\n",
    "        matchindex = np.argmin(facedistance)\n",
    "\n",
    "                    \n",
    "        if matches[matchindex]:\n",
    "                                    \n",
    "            name = classNames[matchindex] \n",
    "            print(name)\n",
    "\n",
    "\n",
    "            y1,x2,y2,x1 = faceloc\n",
    "            y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,0,0),cv2.FILLED) \n",
    "            cv2.putText(img,name,(x1+6,y2-5),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('mask detection',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "\n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e84f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "try:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39cfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df1c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
